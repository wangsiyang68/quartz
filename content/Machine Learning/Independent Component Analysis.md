Identifying the original sources from the mixed soup (unmixing paint?)
- Note the Independence, so means must be non-gaussian 
	- Why non gaussian?
	The non-Gaussianity of the sources is a good measure to estimate a source's independence because it implies that the sources have higher-order statistical dependencies that cannot be captured by the mean and covariance alone. In other words, non-Gaussianity is a measure of the degree of statistical structure in the source signals that is not explained by linear correlation.
	
	In contrast, Gaussian signals are completely characterized by their mean and covariance and do not have any higher-order statistical dependencies. Therefore, if the observed signals are Gaussian, it is impossible to separate them into independent sources using linear transformations.
	
	The non-Gaussianity of the sources is measured by a contrast function, such as negentropy or kurtosis, which is based on the assumption that non-Gaussian sources have higher-order statistical dependencies. By maximizing the non-Gaussianity of the estimated sources, ICA aims to extract the independent sources that generated the observed mixtures.
	
	The non-Gaussianity assumption in ICA is often a reasonable assumption for many real-world signals, such as speech, music, or biological signals, which are typically generated by complex nonlinear processes. However, it is important to note that the non-Gaussianity assumption is not always valid for all types of signals, and there may be cases where other measures of statistical independence, such as mutual information or entropy, may be more appropriate.

#ml 